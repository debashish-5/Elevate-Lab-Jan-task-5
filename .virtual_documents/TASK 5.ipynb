import pandas as pd


df = pd.read_csv('dataset.csv')


df


df.head()


df.tail()


df.info()


df.describe()


df.columns


df.index





from sklearn.model_selection import train_test_split


train_set,test_set = train_test_split(df,test_size=0.2,random_state=42)


train_set


test_set








train_set


# taking feature
feature = train_set.drop('target',axis=1)


#taking labels
labels = train_set['target']


#taking model
from sklearn.linear_model import LogisticRegression


model = LogisticRegression()


model.fit(feature,labels)


import matplotlib.pyplot as plt
import numpy as np

# 1. Prepare Data
feature_test = test_set.drop('target', axis=1)
labels_test = test_set['target'].values # Convert to numpy array
prediction = model.predict(feature_test)

# 2. Set up for visualization
# Only plot the first few samples to avoid a chaotic, unreadable chart
n_samples = 10 
indices = np.arange(n_samples)
width = 0.35 # Width of the bars

# 3. Plotting
plt.figure(figsize=(10, 6))

# Plot Actual
plt.bar(indices - width/2, labels_test[:n_samples], width, label="Original", color='blue', alpha=0.7)

# Plot Predicted
plt.bar(indices + width/2, prediction[:n_samples], width, label="Prediction", color='red', alpha=0.7)

# 4. Styling
plt.xlabel("Sample Index")
plt.ylabel("Target Value")
plt.title("Actual vs Predicted Values (First 10 Samples)")
plt.xticks(indices)
plt.legend()
plt.tight_layout()
plt.show()






from sklearn.metrics import confusion_matrix,consensus_score


score = confusion_matrix(labels_test,prediction)


score





from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.models import Sequential



model = Sequential()


#Adding layers (input,hidden,output)
#first hidden layer
model.add(Dense(units=64,activation='relu',input_dim=13))
#2nd hidden layer
model.add(Dense(units=128,activation='relu'))
#3rd hidden layer
model.add(Dense(units=256,activation='relu'))
#output layer
model.add(Dense(units=1,activation='sigmoid'))




